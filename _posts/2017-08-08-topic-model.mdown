---
title: 潜在トピックモデル
layout: post
categories: 機械学習
tags: [Topic Model, LDA]
---

## Latent Dirichlet Allocation

- 言語モデル
    - 文の生成確率を計算
    - P(吃了吗)=？
- Bag of Words(順序無視、他1-gram)
- Bag of XXX
    - 購買履歴
    - 他画像処理、音声認識、情報検索など
- 教師なし学習
- 「白鵬が単独首位、琴欧州は敗れる。」トピック：相撲、？、？

## LDAの生成過程

- 文章は幾つかのトピックによって生成された（全K個のトピックと仮定）
単語の番号はそのトピックの番号

![adfadf]({{ site.baseurl }}/assets/lda1.jpg)

- トピックごとに単語の生成分布が違う。トピックにXXXのトピックと言うラベルが無い（教師なし学習）

![adfadf]({{ site.baseurl }}/assets/lda2.jpg)

## 多項分布(Multinomial distribution)

- n回試行,取りうる値={1,2,...,K}
- $x_i\in\{1,2,...,K\}$
- $p(x_i=k)=\pi$
- $\boldsymbol{\pi}=\{\pi_1,\pi_2,...,\pi_K\}, \sum\limits_{k=1}^K\pi_k=1$
- $p(x_1,x_2,...,x_n)=\prod\limits_{i=1}^{n}p(x_i)= \prod\limits_{i=1}^{K}\pi_i^{n_k}$
- 各試行の回数だけに興味ある場合

$$\begin{array}{}
&\quad p(\{n_1,n_2,...,n_K\}|\boldsymbol{\pi},n)\\
&= Multi(\{n_1,n_2,...,n_K\}|\boldsymbol{\pi},n)\\
&= C_n^{n_1}C_{n-n_1}^{n_2}...C_{n-\sum_{i=1}^{K-2}n_i}^{n_{k-1}}C_{n_k}^{n_k}\prod\limits_{i=1}^{K}\pi_i^{n_k}\\
&=\frac{n!}{\prod_{k=1}^Kn_k!}\prod\limits_{k=1}^K\pi_k^{n_k}\end{array}$$

- トピックから単語を生成する分布
- 文章のトピックの分布

## ベイズ的統計(Bayesian statistics)

- ベイズの公式

$$P(B_i|A)= \frac{P(A|B_i)P(B_i)}{P(A)}=\frac{P(A|B_i)p(\theta)}{\sum_{i=1}^{N}P(A|B_i)P(B_i)}$$

- 事後分布

$$p(\theta|\boldsymbol{x})=\frac{p(\theta)\prod_{i=1}^n f(x_i|\theta)}{\int_{\Theta}p(\theta)\prod_{i=1}^n f(x_i|\theta)d{\theta}}$$

- ベイズでは分布のパラメータ$\theta$が確率分布すると仮定する

## ディリクレ分布(Dirichlet distribution)


- 多項分布の共役事前分布
- 数式

$$Dir(\boldsymbol{\pi}|\boldsymbol{\alpha})=\frac{\Gamma\left(\alpha_0\right)}{ \prod_{k=1}^{K}\Gamma\left(\alpha_k\right) }\prod_{k=1}^{K}\pi_k^{\alpha_k-1}$$
$$但し、 \left\{\begin{array}{ll}\alpha_0&=\sum_{k=1}^K\alpha_k\\
\Gamma(x)&=(x-1)!\end{array}\right.$$ 

- $\therefore$ ディリクレ分布と多項分布が形式的に同じ：共役事前分布

- $\boldsymbol{\pi}$：確率変数
- $\boldsymbol{\alpha}$：ハイパーパラメータ

## Bayes推定


### 観測値 $\boldsymbol{x}=\{x_1,x_2,...,x_n\}$に対して

- 真の分布： $p^*(x)$
    - 知ることが出来ない
    - 現実のデータは何らかの分布から生成されたとは限らない
    - 数学的仮定

- 統計的生成モデル：$p({x}\|{\phi})$

    - $x_i \sim p(x_i\|\phi)$
    - $p^*(x)$に出来るだけ近づける

- 問題：
    - $p^*(x)$と$p(x\|\phi)$どれだけ近い？

### KL情報量

- 公式

$$KL[p^*(x)\|p(x|\phi)]=\int p^*(x)\log\frac{p^*(x)}{p(x|\phi)}dx.$$

- 性質

$$KL[p^*(x)\|p(x|\phi)] \geq 0$$

$$KL[p^*(x)\|p(x|\phi)] = 0\Leftrightarrow p^*(x)=p(x|\phi)$$

- 以下によって$p(x\vert\phi)$を求める

$$\phi^*= \mathop{\rm argmin}\limits_{\phi}\left\{KL[p^*(x)\|p(x|\phi)]\right\}$$

### 最尤推定, Maximum Likelihood Estimattion, (MLE)

$$KL[p^*(x)\|p(x|\phi)]=\int p^*(x)\log\frac{p^*(x)}{p(x|\phi)}dx.$$

- $p^*(x)$による期待値

$$\begin{array}{}KL[p^*(x)\|p(x|\phi)]&=\int p^*(x)\log\frac{p^*(x)}{p(x|\phi)}dx.\\
&= \mathbb{E}_{p^*(x)}\left[\log\frac{p^*(x)}{p(x|\phi)}\right]\\
&= \mathbb{E}_{p^*(x)}\left[\log{p^*(x)}\right]-\mathbb{E}_{p^*(x)}\left[\log{p(x|\phi)}\right]\\
\end{array}$$

$$\begin{array}{}\phi^*&=\mathop{\rm argmin}\limits_{\phi}\left\{KL[p^*(x)\|p(x|\phi)]\right\}\\
&=\mathop{\rm argmin}\limits_{\phi}\left\{\mathbb{E}_{p^*(x)}\left[\log{p^*(x)}\right]-\mathbb{E}_{p^*(x)}\left[\log{p(x|\phi)}\right]\right\}\\
&=\mathop{\rm argmin}\limits_{\phi}\left\{-\mathbb{E}_{p^*(x)}\left[\log{p(x|\phi)}\right]\right\}\\
&=\mathop{\rm argmax}\limits_{\phi}\left\{\mathbb{E}_{p^*(x)}\left[\log{p(x|\phi)}\right]\right\}\\
\end{array}$$

- 真の分布
$$p^{*}$$
が分からないので
$\mathbb{E}_{p^*(x)}\left[\log{p(x)|\phi)}\right]$
を求めることが出来ない

- 観測データを真の分布からのサンプルとして期待値計算を近似する

$$\mathbb{E}_{p^*(x)}\left[\log{p(x)|\phi)}\right]\approx\frac{1}{n}\sum\limits_{i=1}^n\log p(x_i|\phi)$$

$$\phi_{ML}^*=\mathop{\rm argmax}\limits_{\phi}\left\{\sum\limits_{i=1}^n\log p(x_i|\phi)\right\}$$

### 最大事後確率推定, Maximum a posteriori, (MAP)

$$\phi_{MAP}^*=\mathop{\rm argmax}\limits_{\phi}\left\{\log p(\phi|\eta)+\sum\limits_{i=1}^n\log p(x_i|\phi)\right\}$$

- 過学習防止，汎化能力高い

### 期待事後推定, Expected a posterior, (EAP)

- 新たなデータ$x^*$
$$p(x^*|\boldsymbol{x})=\int p(x^*|\phi)p(\phi|\boldsymbol{x})d\phi= \mathbb{E}_{p(\phi|\boldsymbol{x})}\left[p(x^*|\phi)\right].$$

- ベイズ推定の枠組み


